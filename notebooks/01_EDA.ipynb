{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will have a first look to the 4 initial dataset and concat them in order to work with the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "\n",
    "#### Hugo Cesar Octavio del Sueldo¶\n",
    "#### Jose Lopez Galdon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date:\n",
    "04/12/2020\n",
    "### Version:¶\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load pySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First of all, we will create the sparkContext and we will create the RDD from our files downloaded from the official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Findspark to locate the spark in the system\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "    # Initialize the spark context\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "    # Due to we are going to work with sparkSQL we will introduce the sparksql context\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create objects with the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies = \"../data/01_raw/movies.csv\"\n",
    "data_ratings = \"../data/01_raw/ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Movies dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "raw_movies = spark.read.format(\"csv\") \\\n",
    "                    .option(\"sep\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .load(f'{data_movies}')\n",
    "print(type(raw_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data file loaded into the raw_movies DataFrame.\n",
    "\n",
    "Without getting into *Spark transformations and actions*, the most basic thing we can do to check that we got our DF contents right is to check the first few entries in our data. We can also count() the number of lines loaded from the file into the DF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieId=1, title='Toy Story (1995)', genres='Adventure|Animation|Children|Comedy|Fantasy'),\n",
       " Row(movieId=2, title='Jumanji (1995)', genres='Adventure|Children|Fantasy'),\n",
       " Row(movieId=3, title='Grumpier Old Men (1995)', genres='Comedy|Romance'),\n",
       " Row(movieId=4, title='Waiting to Exhale (1995)', genres='Comedy|Drama|Romance'),\n",
       " Row(movieId=5, title='Father of the Bride Part II (1995)', genres='Comedy')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     # The first 5 observations with take function\n",
    "raw_movies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58098"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     # Count the number of observation\n",
    "raw_movies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the result in more interactive manner (rows under the columns), we can use the show operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|      7|      Sabrina (1995)|      Comedy|Romance|\n",
      "|      8| Tom and Huck (1995)|  Adventure|Children|\n",
      "|      9| Sudden Death (1995)|              Action|\n",
      "|     10|    GoldenEye (1995)|Action|Adventure|...|\n",
      "|     11|American Presiden...|Comedy|Drama|Romance|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     13|        Balto (1995)|Adventure|Animati...|\n",
      "|     14|        Nixon (1995)|               Drama|\n",
      "|     15|Cutthroat Island ...|Action|Adventure|...|\n",
      "|     16|       Casino (1995)|         Crime|Drama|\n",
      "|     17|Sense and Sensibi...|       Drama|Romance|\n",
      "|     18|   Four Rooms (1995)|              Comedy|\n",
      "|     19|Ace Ventura: When...|              Comedy|\n",
      "|     20|  Money Train (1995)|Action|Comedy|Cri...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_movies.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Show the schema\n",
    "raw_movies.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it shows us each column (by name, according to the file header) and its type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "raw_ratings = spark.read.format(\"csv\") \\\n",
    "                    .option(\"sep\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .load(f'{data_ratings}')\n",
    "print(type(raw_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(userId=1, movieId=307, rating=3.5, timestamp=1256677221),\n",
       " Row(userId=1, movieId=481, rating=3.5, timestamp=1256677456),\n",
       " Row(userId=1, movieId=1091, rating=1.5, timestamp=1256677471),\n",
       " Row(userId=1, movieId=1257, rating=4.5, timestamp=1256677460),\n",
       " Row(userId=1, movieId=1449, rating=4.5, timestamp=1256677264)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # The first 5 observations with take function\n",
    "raw_ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|    307|   3.5|1256677221|\n",
      "|     1|    481|   3.5|1256677456|\n",
      "|     1|   1091|   1.5|1256677471|\n",
      "|     1|   1257|   4.5|1256677460|\n",
      "|     1|   1449|   4.5|1256677264|\n",
      "|     1|   1590|   2.5|1256677236|\n",
      "|     1|   1591|   1.5|1256677475|\n",
      "|     1|   2134|   4.5|1256677464|\n",
      "|     1|   2478|   4.0|1256677239|\n",
      "|     1|   2840|   3.0|1256677500|\n",
      "|     1|   2986|   2.5|1256677496|\n",
      "|     1|   3020|   4.0|1256677260|\n",
      "|     1|   3424|   4.5|1256677444|\n",
      "|     1|   3698|   3.5|1256677243|\n",
      "|     1|   3826|   2.0|1256677210|\n",
      "|     1|   3893|   3.5|1256677486|\n",
      "|     2|    170|   3.5|1192913581|\n",
      "|     2|    849|   3.5|1192913537|\n",
      "|     2|   1186|   3.5|1192913611|\n",
      "|     2|   1235|   3.0|1192913585|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Count the number of observation\n",
    "raw_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Show the schema \n",
    "raw_ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27753444"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "     # Count the number of observation    \n",
    "raw_ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to continue with the exploration, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Join both the data frames to add movie data into ratings\n",
    "movie_ratings = raw_ratings.join(other=raw_movies, on=[\"movieId\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27753444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|    307|     1|   3.5|1256677221|Three Colors: Blu...|               Drama|\n",
      "|    481|     1|   3.5|1256677456|   Kalifornia (1993)|      Drama|Thriller|\n",
      "|   1091|     1|   1.5|1256677471|Weekend at Bernie...|              Comedy|\n",
      "|   1257|     1|   4.5|1256677460|Better Off Dead.....|      Comedy|Romance|\n",
      "|   1449|     1|   4.5|1256677264|Waiting for Guffm...|              Comedy|\n",
      "|   1590|     1|   2.5|1256677236|Event Horizon (1997)|Horror|Sci-Fi|Thr...|\n",
      "|   1591|     1|   1.5|1256677475|        Spawn (1997)|Action|Adventure|...|\n",
      "|   2134|     1|   4.5|1256677464|Weird Science (1985)|Comedy|Fantasy|Sc...|\n",
      "|   2478|     1|   4.0|1256677239|¡Three Amigos! (1...|      Comedy|Western|\n",
      "|   2840|     1|   3.0|1256677500|     Stigmata (1999)|      Drama|Thriller|\n",
      "|   2986|     1|   2.5|1256677496|    RoboCop 2 (1990)|Action|Crime|Sci-...|\n",
      "|   3020|     1|   4.0|1256677260| Falling Down (1993)|        Action|Drama|\n",
      "|   3424|     1|   4.5|1256677444|Do the Right Thin...|               Drama|\n",
      "|   3698|     1|   3.5|1256677243|Running Man, The ...|       Action|Sci-Fi|\n",
      "|   3826|     1|   2.0|1256677210|   Hollow Man (2000)|Horror|Sci-Fi|Thr...|\n",
      "|   3893|     1|   3.5|1256677486|  Nurse Betty (2000)|Comedy|Crime|Dram...|\n",
      "|    170|     2|   3.5|1192913581|      Hackers (1995)|Action|Adventure|...|\n",
      "|    849|     2|   3.5|1192913537|Escape from L.A. ...|Action|Adventure|...|\n",
      "|   1186|     2|   3.5|1192913611|Sex, Lies, and Vi...|               Drama|\n",
      "|   1235|     2|   3.0|1192913585|Harold and Maude ...|Comedy|Drama|Romance|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
