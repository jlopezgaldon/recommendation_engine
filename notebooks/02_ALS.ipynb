{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "\n",
    "#### Hugo Cesar Octavio del Sueldo\n",
    "#### Jose Lopez Galdon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date:\n",
    "15/01/2021\n",
    "### Version:\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load pySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First of all, we will create the sparkContext and we will create the RDD from our files downloaded from the official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Findspark to locate the spark in the system\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "\n",
    "    # Initialize the spark context\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "    # Due to we are going to work with sparkSQL we will introduce the sparksql context\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "    # Visualitation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "    # Handy\n",
    "from handyspark import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create objects with the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies = \"../data/01_raw/movies.csv\"\n",
    "data_ratings = \"../data/01_raw/ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Movies dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "raw_movies = spark.read.format(\"csv\") \\\n",
    "                       .option(\"sep\", \",\") \\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .option(\"header\", \"true\") \\\n",
    "                       .load(f'{data_movies}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "raw_ratings = spark.read.format(\"csv\") \\\n",
    "                        .option(\"sep\", \",\") \\\n",
    "                        .option(\"inferSchema\", \"true\") \\\n",
    "                        .option(\"header\", \"true\") \\\n",
    "                        .load(f'{data_ratings}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to continue with the exploration, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Join both the data frames to add movie data into ratings\n",
    "movie_ratings = raw_ratings.join(other=raw_movies, on=[\"movieId\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|    307|     1|   3.5|1256677221|Three Colors: Blu...|               Drama|\n",
      "|    481|     1|   3.5|1256677456|   Kalifornia (1993)|      Drama|Thriller|\n",
      "|   1091|     1|   1.5|1256677471|Weekend at Bernie...|              Comedy|\n",
      "|   1257|     1|   4.5|1256677460|Better Off Dead.....|      Comedy|Romance|\n",
      "|   1449|     1|   4.5|1256677264|Waiting for Guffm...|              Comedy|\n",
      "|   1590|     1|   2.5|1256677236|Event Horizon (1997)|Horror|Sci-Fi|Thr...|\n",
      "|   1591|     1|   1.5|1256677475|        Spawn (1997)|Action|Adventure|...|\n",
      "|   2134|     1|   4.5|1256677464|Weird Science (1985)|Comedy|Fantasy|Sc...|\n",
      "|   2478|     1|   4.0|1256677239|Â¡Three Amigos! (1...|      Comedy|Western|\n",
      "|   2840|     1|   3.0|1256677500|     Stigmata (1999)|      Drama|Thriller|\n",
      "|   2986|     1|   2.5|1256677496|    RoboCop 2 (1990)|Action|Crime|Sci-...|\n",
      "|   3020|     1|   4.0|1256677260| Falling Down (1993)|        Action|Drama|\n",
      "|   3424|     1|   4.5|1256677444|Do the Right Thin...|               Drama|\n",
      "|   3698|     1|   3.5|1256677243|Running Man, The ...|       Action|Sci-Fi|\n",
      "|   3826|     1|   2.0|1256677210|   Hollow Man (2000)|Horror|Sci-Fi|Thr...|\n",
      "|   3893|     1|   3.5|1256677486|  Nurse Betty (2000)|Comedy|Crime|Dram...|\n",
      "|    170|     2|   3.5|1192913581|      Hackers (1995)|Action|Adventure|...|\n",
      "|    849|     2|   3.5|1192913537|Escape from L.A. ...|Action|Adventure|...|\n",
      "|   1186|     2|   3.5|1192913611|Sex, Lies, and Vi...|               Drama|\n",
      "|   1235|     2|   3.0|1192913585|Harold and Maude ...|Comedy|Drama|Romance|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Show the dataset\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, we have our new dataset ready to perform the ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie_ratings dataframe is  99.82% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = movie_ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct Id's\n",
    "num_users = movie_ratings.select(\"userId\").distinct().count()\n",
    "num_items = movie_ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of items\n",
    "denominator = num_users * num_items\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator * 1.0)/ denominator) * 100\n",
    "print(\"The movie_ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you will be think what is Sparcity? well this is answer in the theory part (`00_THEORY`). Anyway, we will explain a breaf summary about it.\n",
    "\n",
    "In a real world setting, the vast majority of movies receive very few or even no ratings at all by users. A variable with sparse data is one in which a relatively high percentage of the variable's cells do not contain actual data. Such \"empty,\" or NA, values take up storage space in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
