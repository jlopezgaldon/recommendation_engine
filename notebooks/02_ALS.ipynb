{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors:\n",
    "\n",
    "#### Hugo Cesar Octavio del Sueldo\n",
    "#### Jose Lopez Galdon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date:\n",
    "15/01/2021\n",
    "### Version:\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load pySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First of all, we will create the sparkContext and we will create the RDD from our files downloaded from the official website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "    # Findspark to locate the spark in the system\n",
    "#import findspark\n",
    "#findspark.init()\n",
    "\n",
    "    # Initialize the spark context\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "\n",
    "    # Due to we are going to work with sparkSQL we will introduce the sparksql context\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "# data science imports\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "    # Visualitation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "    # Handy\n",
    "from handyspark import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will create objects with the file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies = \"../data/01_raw/movies.csv\"\n",
    "data_ratings = \"../data/01_raw/ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Movies dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_movies = spark.read.format(\"csv\") \\\n",
    "                       .option(\"sep\", \",\") \\\n",
    "                       .option(\"inferSchema\", \"true\") \\\n",
    "                       .option(\"header\", \"true\") \\\n",
    "                       .load(f'{data_movies}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`spark.read`**: It is necesary to load the csv file.\n",
    "- format(\"csv\"): Means the format of the file.\n",
    "\n",
    "- option(\"sep\", \",\"): It establish the kind of spearator, in this case ','.\n",
    "\n",
    "- option(\"inferSchema\", \"true\"): We set spark to infer the type of schema.\n",
    "\n",
    "- option(\"header\", \"true\"): We say to spark that the file has a header.\n",
    "\n",
    "- load(f'{datos_movies}'): Path file.\n",
    "\n",
    "This code was written in Scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_ratings = spark.read.format(\"csv\") \\\n",
    "                        .option(\"sep\", \",\") \\\n",
    "                        .option(\"inferSchema\", \"true\") \\\n",
    "                        .option(\"header\", \"true\") \\\n",
    "                        .load(f'{data_ratings}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to continue with the exploration, we will merge both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Join both the data frames to add movie data into ratings\n",
    "movie_ratings = raw_ratings.join(other=raw_movies, on=[\"movieId\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|               title|              genres|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "|    307|     1|   3.5|1256677221|Three Colors: Blu...|               Drama|\n",
      "|    481|     1|   3.5|1256677456|   Kalifornia (1993)|      Drama|Thriller|\n",
      "|   1091|     1|   1.5|1256677471|Weekend at Bernie...|              Comedy|\n",
      "|   1257|     1|   4.5|1256677460|Better Off Dead.....|      Comedy|Romance|\n",
      "|   1449|     1|   4.5|1256677264|Waiting for Guffm...|              Comedy|\n",
      "|   1590|     1|   2.5|1256677236|Event Horizon (1997)|Horror|Sci-Fi|Thr...|\n",
      "|   1591|     1|   1.5|1256677475|        Spawn (1997)|Action|Adventure|...|\n",
      "|   2134|     1|   4.5|1256677464|Weird Science (1985)|Comedy|Fantasy|Sc...|\n",
      "|   2478|     1|   4.0|1256677239|Â¡Three Amigos! (1...|      Comedy|Western|\n",
      "|   2840|     1|   3.0|1256677500|     Stigmata (1999)|      Drama|Thriller|\n",
      "|   2986|     1|   2.5|1256677496|    RoboCop 2 (1990)|Action|Crime|Sci-...|\n",
      "|   3020|     1|   4.0|1256677260| Falling Down (1993)|        Action|Drama|\n",
      "|   3424|     1|   4.5|1256677444|Do the Right Thin...|               Drama|\n",
      "|   3698|     1|   3.5|1256677243|Running Man, The ...|       Action|Sci-Fi|\n",
      "|   3826|     1|   2.0|1256677210|   Hollow Man (2000)|Horror|Sci-Fi|Thr...|\n",
      "|   3893|     1|   3.5|1256677486|  Nurse Betty (2000)|Comedy|Crime|Dram...|\n",
      "|    170|     2|   3.5|1192913581|      Hackers (1995)|Action|Adventure|...|\n",
      "|    849|     2|   3.5|1192913537|Escape from L.A. ...|Action|Adventure|...|\n",
      "|   1186|     2|   3.5|1192913611|Sex, Lies, and Vi...|               Drama|\n",
      "|   1235|     2|   3.0|1192913585|Harold and Maude ...|Comedy|Drama|Romance|\n",
      "+-------+------+------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    # Show the dataset\n",
    "movie_ratings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, we have our new dataset ready to perform the ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparcity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie_ratings dataframe is  99.82% empty.\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of ratings in the dataset\n",
    "numerator = movie_ratings.select(\"rating\").count()\n",
    "\n",
    "# Count the number of distinct Id's\n",
    "num_users = movie_ratings.select(\"userId\").distinct().count()\n",
    "num_items = movie_ratings.select(\"movieId\").distinct().count()\n",
    "\n",
    "# Set the denominator equal to the number of users multiplied by the number of items\n",
    "denominator = num_users * num_items\n",
    "\n",
    "# Divide the numerator by the denominator\n",
    "sparsity = (1.0 - (numerator * 1.0)/ denominator) * 100\n",
    "print(\"The movie_ratings dataframe is \", \"%.2f\" % sparsity + \"% empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you will be think what is Sparcity? well this is answer in the theory part (`00_THEORY`). Anyway, we will explain a breaf summary about it.\n",
    "\n",
    "In a real world setting, the vast majority of movies receive very few or even no ratings at all by users. A variable with sparse data is one in which a relatively high percentage of the variable's cells do not contain actual data. Such \"empty,\" or NA, values take up storage space in the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ALS based approach for training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reload data\n",
    "\n",
    "- Split data into train, validation, test\n",
    "\n",
    "- ALS model selection and evaluation\n",
    "\n",
    "- Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload data\n",
    "\n",
    "We will use an RDD-based API from pyspark.mllib to predict the ratings, so let's reload \"ratings.csv\" using sc.textFile and then convert it to the form of (user, item, rating) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 307, 3.5), (1, 481, 3.5), (1, 1091, 1.5)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # load data\n",
    "movie_rating = sc.textFile(\"../data/01_raw/ratings.csv\")\n",
    "    \n",
    "    # preprocess data -- only need [\"userId\", \"movieId\", \"rating\"]\n",
    "header = movie_rating.take(1)[0]\n",
    "rating_data = movie_rating \\\n",
    "    .filter(lambda line: line!=header) \\\n",
    "    .map(lambda line: line.split(\",\")) \\\n",
    "    .map(lambda tokens: (int(tokens[0]), int(tokens[1]), float(tokens[2]))) \\\n",
    "    .cache()\n",
    "\n",
    "    # check three rows\n",
    "rating_data.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into training/validation/testing sets using a 6/2/2 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[7] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validation, test = rating_data.randomSplit([6, 2, 2], seed=1322)\n",
    "    \n",
    "    # cache data\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS model selection and evaluation\n",
    "\n",
    "With the ALS model, we can use a grid search to find the optimal hyperparameters. Hyper-parameter tuning is a highly recurring task in many machine learning projects. We can code it up in a function to speed up the tuning iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ALS(train_data, validation_data, num_iters, reg_param, ranks):\n",
    "    \"\"\"\n",
    "    Grid Search Function to select the best model based on RMSE of hold-out data\n",
    "    \"\"\"\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    for rank in ranks:\n",
    "        for reg in reg_param:\n",
    "            # train ALS model\n",
    "            model = ALS.train(\n",
    "                ratings=train_data,    # (userID, productID, rating) tuple\n",
    "                iterations=num_iters,\n",
    "                rank=rank,\n",
    "                lambda_=reg,           # regularization param\n",
    "                seed=99)\n",
    "            # make prediction\n",
    "            valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
    "            predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "            # get the rating result\n",
    "            ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "            # get the RMSE\n",
    "            MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "            error = math.sqrt(MSE)\n",
    "            print('{} latent factors and regularization = {}: validation RMSE is {}'.format(rank, reg, error))\n",
    "            if error < min_error:\n",
    "                min_error = error\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 latent factors and regularization = 0.001: validation RMSE is 0.8775082179909707\n",
      "8 latent factors and regularization = 0.01: validation RMSE is 0.8488176181700141\n",
      "8 latent factors and regularization = 0.05: validation RMSE is 0.8174662888523746\n",
      "8 latent factors and regularization = 0.1: validation RMSE is 0.8186956131628501\n",
      "8 latent factors and regularization = 0.2: validation RMSE is 0.8648807106571224\n",
      "10 latent factors and regularization = 0.001: validation RMSE is 0.8893024013927613\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 0.8550543356099547\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 0.8188017188203359\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 0.8186776553616125\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 0.8648282885836029\n",
      "12 latent factors and regularization = 0.001: validation RMSE is 0.8987080109807737\n",
      "12 latent factors and regularization = 0.01: validation RMSE is 0.8623524739984955\n",
      "12 latent factors and regularization = 0.05: validation RMSE is 0.8186632664878863\n",
      "12 latent factors and regularization = 0.1: validation RMSE is 0.8203895542184353\n",
      "12 latent factors and regularization = 0.2: validation RMSE is 0.8661129922721681\n",
      "14 latent factors and regularization = 0.001: validation RMSE is 0.907180256777108\n",
      "14 latent factors and regularization = 0.01: validation RMSE is 0.8659365245001085\n",
      "14 latent factors and regularization = 0.05: validation RMSE is 0.8130488086451669\n",
      "14 latent factors and regularization = 0.1: validation RMSE is 0.8159561926558714\n",
      "14 latent factors and regularization = 0.2: validation RMSE is 0.8647051248493091\n",
      "16 latent factors and regularization = 0.001: validation RMSE is 0.9156291624821637\n",
      "16 latent factors and regularization = 0.01: validation RMSE is 0.869179077855428\n",
      "16 latent factors and regularization = 0.05: validation RMSE is 0.8160225323374295\n",
      "16 latent factors and regularization = 0.1: validation RMSE is 0.8184566793547831\n",
      "16 latent factors and regularization = 0.2: validation RMSE is 0.865875322475069\n",
      "18 latent factors and regularization = 0.001: validation RMSE is 0.9258793893779736\n",
      "18 latent factors and regularization = 0.01: validation RMSE is 0.8760201032082375\n",
      "18 latent factors and regularization = 0.05: validation RMSE is 0.8159803425359616\n",
      "18 latent factors and regularization = 0.1: validation RMSE is 0.8181390963268458\n",
      "18 latent factors and regularization = 0.2: validation RMSE is 0.8657899406428632\n",
      "20 latent factors and regularization = 0.001: validation RMSE is 0.9357650631959852\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 0.879247974867675\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 0.8162619220615888\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.8208754170327797\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 0.8670159935517203\n",
      "\n",
      "The best model has 14 latent factors and regularization = 0.05\n",
      "Total Runtime: 11971.00 seconds\n"
     ]
    }
   ],
   "source": [
    "# hyper-param config\n",
    "num_iterations = 10\n",
    "ranks = [8, 10, 12, 14, 16, 18, 20]\n",
    "reg_params = [0.001, 0.01, 0.05, 0.1, 0.2]\n",
    "\n",
    "# grid search and select best model\n",
    "start_time = time.time()\n",
    "final_model = train_ALS(train, validation, num_iterations, reg_params, ranks)\n",
    "\n",
    "print ('Total Runtime: {:.2f} seconds'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning, we found the best choice of hyper-parameters: `maxIter=10`, `regParam=0.05`, `rank=14`\n",
    "\n",
    "The RMSE for the best model is 0.8130 which means that on average the model predicts 0.8133 above or below values of the original ratings matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS model learning curve\n",
    "\n",
    "As we increase number of iterations in training ALS, we can see how RMSE changes and whether or not model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(arr_iters, train_data, validation_data, reg, rank):\n",
    "    \"\"\"\n",
    "    Plot function to show learning curve of ALS\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for num_iters in arr_iters:\n",
    "        # train ALS model\n",
    "        model = ALS.train(\n",
    "            ratings=train_data,    # (userID, productID, rating) tuple\n",
    "            iterations=num_iters,\n",
    "            rank=rank,\n",
    "            lambda_=reg,           # regularization param\n",
    "            seed=99)\n",
    "        # make prediction\n",
    "        valid_data = validation_data.map(lambda p: (p[0], p[1]))\n",
    "        predictions = model.predictAll(valid_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "        # get the rating result\n",
    "        ratesAndPreds = validation_data.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "        # get the RMSE\n",
    "        MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "        error = math.sqrt(MSE)\n",
    "        # add to errors\n",
    "        errors.append(error)\n",
    "\n",
    "    # plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(arr_iters, errors)\n",
    "    plt.xlabel('number of iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.title('ALS Learning Curve')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create an array of num_iters\n",
    "iter_array = list(range(1, 11))\n",
    "# create learning curve plot\n",
    "plot_learning_curve(iter_array, train, validation, 0.05, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 3 iterations, alternating gradient descend starts to converge at an error around 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, make a prediction and check the testing error using out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample RMSE of rating predictions is 0.813280396818649\n"
     ]
    }
   ],
   "source": [
    "        # make prediction using test data\n",
    "test_data = test.map(lambda p: (p[0], p[1]))\n",
    "predictions = final_model.predictAll(test_data).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    \n",
    "    # get the rating result\n",
    "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "\n",
    "    # get the RMSE\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "error = math.sqrt(MSE)\n",
    "print('The out-of-sample RMSE of rating predictions is', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persisting the model\n",
    "\n",
    "Optionally, we might want to persist the base model for later use in our on-line recommendations. Although a new model is generated everytime we have new user ratings, it might be worth it to store the current one, in order to save time when starting up the server, etc. We might also save time if we persist some of the RDDs we have generated, specially those that took longer to process. For example, the following lines save and load a ALS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_path = os.path.join('../data/02_models', 'movie_lens_als')\n",
    "\n",
    "# Save and load model\n",
    "final_model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make movie recommendation to myself\n",
    "\n",
    "We need to define a function that takes new user's movie rating and output top 10 recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To productize a model, we need to build a work flow around the model. Typical ML work flow roughly starts with data preparation via pre-defined set of ETL jobs, offline/online model training, then ingesting trained models to web services for production. In our case, we are going to build a very minimum version of movie recommender that just does the job. Our work flow is following:\n",
    "\n",
    "- A new user inputs his/her favorite movies, then system create new user-movie interaction samples for the model\n",
    "\n",
    "- System retrains ALS model on data with the new inputs\n",
    "\n",
    "- System creates movie data for inference (in my case, I sample all movies from the data)\n",
    "\n",
    "- System make rating predictions on all movies for that user\n",
    "\n",
    "- System outputs top N movie recommendations for that user based on the ranking of movie rating predictions\n",
    "\n",
    "Here is the source code for our MVP recommender system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movieId(df_movies, fav_movie_list):\n",
    "    \"\"\"\n",
    "    return all movieId(s) of user's favorite movies\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_movies: spark Dataframe, movies data\n",
    "    \n",
    "    fav_movie_list: list, user's list of favorite movies\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    movieId_list: list of movieId(s)\n",
    "    \"\"\"\n",
    "    movieId_list = []\n",
    "    for movie in fav_movie_list:\n",
    "        movieIds = df_movies \\\n",
    "            .filter(raw_movies.title.like('%{}%'.format(movie))) \\\n",
    "            .select('movieId') \\\n",
    "            .rdd \\\n",
    "            .map(lambda r: r[0]) \\\n",
    "            .collect()\n",
    "        movieId_list.extend(movieIds)\n",
    "    return list(set(movieId_list))\n",
    "\n",
    "\n",
    "def add_new_user_to_data(train_data, movieId_list, spark_context):\n",
    "    \"\"\"\n",
    "    add new rows with new user, user's movie and ratings to\n",
    "    existing train data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark RDD, ratings data\n",
    "    \n",
    "    movieId_list: list, list of movieId(s)\n",
    "\n",
    "    spark_context: Spark Context object\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    new train data with the new user's rows\n",
    "    \"\"\"\n",
    "    # get new user id\n",
    "    new_id = train_data.map(lambda r: r[0]).max() + 1\n",
    "    # get max rating\n",
    "    max_rating = train_data.map(lambda r: r[2]).max()\n",
    "    # create new user rdd\n",
    "    user_rows = [(new_id, movieId, max_rating) for movieId in movieId_list]\n",
    "    new_rdd = spark_context.parallelize(user_rows)\n",
    "    # return new train data\n",
    "    return train_data.union(new_rdd)\n",
    "\n",
    "\n",
    "def get_inference_data(train_data, df_movies, movieId_list):\n",
    "    \"\"\"\n",
    "    return a rdd with the userid and all movies (except ones in movieId_list)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_data: spark RDD, ratings data\n",
    "\n",
    "    df_movies: spark Dataframe, movies data\n",
    "    \n",
    "    movieId_list: list, list of movieId(s)\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    inference data: Spark RDD\n",
    "    \"\"\"\n",
    "    # get new user id\n",
    "    new_id = train_data.map(lambda r: r[0]).max() + 1\n",
    "    # return inference rdd\n",
    "    return df_movies.rdd \\\n",
    "        .map(lambda r: r[0]) \\\n",
    "        .distinct() \\\n",
    "        .filter(lambda x: x not in movieId_list) \\\n",
    "        .map(lambda x: (new_id, x))\n",
    "\n",
    "\n",
    "def make_recommendation(best_model_params, ratings_data, df_movies, \n",
    "                        fav_movie_list, n_recommendations, spark_context):\n",
    "    \"\"\"\n",
    "    return top n movie recommendation based on user's input list of favorite movies\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    best_model_params: dict, {'iterations': iter, 'rank': rank, 'lambda_': reg}\n",
    "\n",
    "    ratings_data: spark RDD, ratings data\n",
    "\n",
    "    df_movies: spark Dataframe, movies data\n",
    "\n",
    "    fav_movie_list: list, user's list of favorite movies\n",
    "\n",
    "    n_recommendations: int, top n recommendations\n",
    "\n",
    "    spark_context: Spark Context object\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    list of top n movie recommendations\n",
    "    \"\"\"\n",
    "    # modify train data by adding new user's rows\n",
    "    movieId_list = get_movieId(df_movies, fav_movie_list)\n",
    "    train_data = add_new_user_to_data(ratings_data, movieId_list, spark_context)\n",
    "    \n",
    "    # train best ALS\n",
    "    model = ALS.train(\n",
    "        ratings=train_data,\n",
    "        iterations=best_model_params.get('iterations', None),\n",
    "        rank=best_model_params.get('rank', None),\n",
    "        lambda_=best_model_params.get('lambda_', None),\n",
    "        seed=99)\n",
    "    \n",
    "    # get inference rdd\n",
    "    inference_rdd = get_inference_data(ratings_data, df_movies, movieId_list)\n",
    "    \n",
    "    # inference\n",
    "    predictions = model.predictAll(inference_rdd).map(lambda r: (r[1], r[2]))\n",
    "    \n",
    "    # get top n movieId\n",
    "    topn_rows = predictions.sortBy(lambda r: r[1], ascending=False).take(n_recommendations)\n",
    "    topn_ids = [r[0] for r in topn_rows]\n",
    "    \n",
    "    # return movie titles\n",
    "    return df_movies.filter(raw_movies.movieId.isin(topn_ids)) \\\n",
    "                    .select('title') \\\n",
    "                    .rdd \\\n",
    "                    .map(lambda r: r[0]) \\\n",
    "                    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letâs Make Some Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we implemented the ALS recommender system in a python script as a small Pyspark program, we can submit our spark application to a cluster with Client Deploy Mode or Cluster Deploy Mode and enjoy the power of distributed computing.\n",
    "\n",
    "Finally, we are done with the technical details and implementations. Now letâs ask our recommender for some movie recommendations. I will pretend a new user and input my favorite movie âIron Manâ again into this new recommender system. Letâs see what movies it recommends to me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Iron Man:\n",
      "1: Scarlet Dove, The (Tulipunainen kyyhkynen) (1961)\n",
      "2: Pearl Jam: Immagine in Cornice - Live in Italy 2006 (2007)\n",
      "3: Presumed Guilty (Presunto culpable) (2008)\n",
      "4: The Veil of Twilight (2014)\n",
      "5: Melhores do Mundo - Hermanoteu na Terra de Godah (2009)\n",
      "6: Hunterrr (2015)\n",
      "7: The Flying Dagger (1969)\n",
      "8: Liar Game: The Final Stage (2010)\n",
      "9: Heroes Above All (2017)\n",
      "10: Extinct Pink (1969)\n"
     ]
    }
   ],
   "source": [
    "# my favorite movies\n",
    "my_favorite_movies = ['Iron Man']\n",
    "\n",
    "# get recommends\n",
    "recommends = make_recommendation(\n",
    "    best_model_params={'iterations': 10, 'rank': 14, 'lambda_': 0.05}, \n",
    "    ratings_data=rating_data, \n",
    "    df_movies=raw_movies, \n",
    "    fav_movie_list=my_favorite_movies, \n",
    "    n_recommendations=10, \n",
    "    spark_context=sc)\n",
    "\n",
    "print('Recommendations for {}:'.format(my_favorite_movies[0]))\n",
    "for i, title in enumerate(recommends):\n",
    "    print('{0}: {1}'.format(i+1, title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list of movie recommendations looks good for an action movie like Iron Man. The recommender not only recommends movies outside of years between 2007 and 2009 periods, but also recommends movies that were less known. So this can offer users some elements of suprise so that users won't get bored by getting the same popular movies all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
